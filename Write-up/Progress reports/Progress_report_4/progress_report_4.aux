\relax 
\citation{griffin2014sequential}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gibbs sampler}}{1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Particle filter to update cluster allocations}}{1}}
\newlabel{alg:pf}{{2}{1}}
\newlabel{eq:likelihood}{{1}{1}}
\newlabel{eq:phi}{{2}{1}}
\newlabel{eq:gamma}{{3}{1}}
\newlabel{fig:noshuffle}{{}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Cluster allocation agreement for mixture of Gaussian data with two clusters. Darker colours indicate greater agreement of allocations across runs of the algorithm. The smaller panels represent the posterior similarity matrix for each dataset, while the larger panel represents the consensus. The data are not shuffled prior to running the particle filter.}}{2}}
\newlabel{fig:shuffle}{{}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Cluster allocation agreement for mixture of Gaussian data with two clusters. Darker colours indicate greater agreement of allocations across runs of the algorithm. The smaller panels represent the posterior similarity matrix for each dataset, while the larger panel represents the consensus. The data are shuffled prior to each run of the particle filter.}}{3}}
\newlabel{fig:testdata}{{}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Synthetic data used for testing with two very distinct clusters defined by a gaussian distribution.}}{4}}
\newlabel{fig:gaussiandata}{{}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Synthetic data used for testing with five non-distinct clusters each originating from a gaussian distribution.}}{5}}
\bibstyle{plain}
\bibdata{bibliography.bib}
\bibcite{griffin2014sequential}{1}
\newlabel{fig:gaussiancluster}{{}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Posterior similarity matrix for mixture of Gaussian data with five clusters. Darker colours indicate greater agreement of allocations across runs of the algorithm. The smaller panels represent the posterior similarity matrix for each dataset, while the larger panel represents the consensus. The algorithm is aiming to looking to partition the data into 10 clusters, however it appears to find the 5 true clusters.}}{6}}
